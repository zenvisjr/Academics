# -*- coding: utf-8 -*-
"""ADHD_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ovi91flD58MdlKqRE_R1GTyqIK3tsBWu
"""

# Required Libraries
# from google.colab import drive
# drive.mount('/content/drive')

# Load ADHD dataset and handle missing values
missing_value_formats = ["pending"]
adhd_data = pd.read_csv('Dataset_ADHD200_phenotypic.csv', na_values=missing_value_formats)

# Display initial information and clean the data
adhd_data.info()
adhd_data.head()
adhd_data.isnull().sum()
adhd_data = adhd_data.drop(adhd_data.columns[[0, 5, 7, 19, 20, 21, 23]], axis=1)
adhd_data.ffill(inplace=True)  # Forward fill for missing data
print(adhd_data[adhd_data.duplicated()])
adhd_data.describe()

# Replace 'Male' with 0 and 'Female' with 1 in the 'Gender' column
adhd_data['Gender'] = adhd_data['Gender'].replace({'Male': 0, 'Female': 1})

# Modern countplot for 'Gender' with improved readability
plt.figure(figsize=(10, 6))
sns.countplot(x='Gender', data=adhd_data, palette='Set2')
plt.title('Gender Distribution', fontsize=18, fontweight='bold')
plt.xlabel('Gender', fontsize=16)
plt.ylabel('Count', fontsize=16)
plt.xticks(ticks=[0, 1], labels=['0 (Male)', '1 (Female)'], rotation=0, fontsize=14)  # Custom labels
plt.yticks(fontsize=14)
plt.show()

# Assuming the 'DX' column contains the values 0, 1, 2, 3, we will map them to descriptive names
diagnosis_labels = {0: 'Typically Developing Children',
                    1: 'ADHD-Combined',
                    2: 'ADHD-Hyperactive/Impulsive',
                    3: 'ADHD-Inattentive'}

# Replace numerical diagnosis codes with descriptive labels
adhd_data['DX'] = adhd_data['DX'].map(diagnosis_labels)

# Modern countplot for 'DX' (Diagnosis) with improved readability
plt.figure(figsize=(10, 6))
sns.countplot(x='DX', data=adhd_data, palette='Set2')
plt.title('ADHD Diagnosis Distribution', fontsize=18, fontweight='bold')
plt.xlabel('Diagnosis', fontsize=16)
plt.ylabel('Count', fontsize=16)
plt.xticks(rotation=45, ha='right', fontsize=14)
plt.yticks(fontsize=14)
plt.show()

# Improved barplot for 'DX' vs 'ADHD Index' with 'Gender' as hue
plt.figure(figsize=(12, 8))
sns.barplot(x='DX', y='ADHD Index', hue='Gender', data=adhd_data, palette='spring')

# Add title and labels with improved font sizes
plt.title('ADHD Index by Diagnosis and Gender', fontsize=20, fontweight='bold')
plt.xlabel('Diagnosis', fontsize=16)
plt.ylabel('ADHD Index', fontsize=16)

# Improve x-ticks and y-ticks readability
plt.xticks(rotation=45, ha='right', fontsize=14)
plt.yticks(fontsize=14)

# Add legend title and improve its appearance
plt.legend(title='Gender', title_fontsize='14', fontsize='12', loc='upper right')

# Display the plot
plt.tight_layout()  # Ensures no clipping of axis labels
plt.show()

# Improved barplot for 'DX' vs 'Inattentive' with 'Gender' as hue
plt.figure(figsize=(12, 8))
sns.barplot(x='DX', y='Inattentive', hue='Gender', data=adhd_data, palette='spring')

# Add title and labels with improved font sizes
plt.title('Inattentive Scores by Diagnosis and Gender', fontsize=20, fontweight='bold')
plt.xlabel('Diagnosis', fontsize=16)
plt.ylabel('Inattentive Score', fontsize=16)

# Improve x-ticks and y-ticks readability
plt.xticks(rotation=45, ha='right', fontsize=14)
plt.yticks(fontsize=14)

# Add legend title and improve its appearance
plt.legend(title='Gender', title_fontsize='14', fontsize='12', loc='upper right')

# Display the plot
plt.tight_layout()  # Ensures no clipping of axis labels
plt.show()

# Modern countplot for 'IQ Measure' with improved readability
plt.figure(figsize=(10, 6))
sns.countplot(x='IQ Measure', data=adhd_data, palette='Set3')
plt.title('IQ Measure Distribution', fontsize=18, fontweight='bold')
plt.xlabel('IQ Measure', fontsize=16)
plt.ylabel('Count', fontsize=16)
plt.xticks(rotation=45, ha='right', fontsize=14)
plt.yticks(fontsize=14)
plt.show()

# Modern Pie chart for ADHD distribution with better labels
types = ['Typically Developing Children', 'ADHD-Combined', 'ADHD-Hyperactive/Impulsive', 'ADHD-Inattentive']
sizes = [94, 50, 32, 21]
colors = ['#ffcc00', '#66b3ff', '#ff6666', '#99ff99']  # Modern color palette
explode = (0.1, 0, 0, 0)

plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=types, colors=colors, autopct='%1.1f%%', explode=explode, pctdistance=0.5, shadow=True, startangle=140)
plt.title('ADHD Distribution by Type', fontsize=18, fontweight='bold')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

# Prepare the data for model training
X = adhd_data.drop(columns=['DX', 'ID'], axis=1)
Y = adhd_data['DX']

# Split the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Apply PCA for dimensionality reduction (optional)
pca = PCA(n_components=5)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)

# Define models for comparison
models = {
    'SVM': svm.SVC(kernel='linear'),
    'Decision Tree': DecisionTreeClassifier(),
    'Logistic Regression': LogisticRegression(),
    'KNN': KNeighborsClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'XGBoost': XGBClassifier(),
    'Neural Network': tf.keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ])
}

# Compile and train the Neural Network model
models['Neural Network'].compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Store model performance
results = {}

# Train and evaluate each model
for name, model in models.items():
    if name == 'Neural Network':
        history = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)
        _, accuracy = model.evaluate(X_test, Y_test)
    else:
        model.fit(X_train, Y_train)
        Y_pred = model.predict(X_test)
        accuracy = accuracy_score(Y_test, Y_pred)

    ############### Improvements for Accuracy Begin ###############
    if name != 'Neural Network' and name != 'SVM':  # Example hyperparameter tuning for Random Forest & XGBoost
        if name == 'Random Forest':
            param_grid = {
                'n_estimators': [100, 200, 300],
                'max_depth': [10, 20, None],
                'min_samples_split': [2, 5],
                'min_samples_leaf': [1, 2]
            }
            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
            grid_search.fit(X_train, Y_train)
            best_model = grid_search.best_estimator_  # This will store the actual model object
            accuracy = accuracy_score(Y_test, best_model.predict(X_test))
            print(f"Updated Random Forest Accuracy after tuning: {accuracy:.4f}")

        if name == 'XGBoost':
            param_grid_xgb = {
                'n_estimators': [100, 150, 200],
                'max_depth': [6, 10, 12],
                'learning_rate': [0.01, 0.1, 0.2]
            }
            grid_search_xgb = GridSearchCV(estimator=model, param_grid=param_grid_xgb, cv=3, n_jobs=-1, verbose=2)
            grid_search_xgb.fit(X_train, Y_train)
            best_model_xgb = grid_search_xgb.best_estimator_  # This will store the actual model object
            accuracy = accuracy_score(Y_test, best_model_xgb.predict(X_test))
            print(f"Updated XGBoost Accuracy after tuning: {accuracy:.4f}")

    # Neural Network Architecture Improvement - Add Dropout
    if name == 'Neural Network':
        model.add(layers.Dropout(0.3))  # Adding Dropout to prevent overfitting

    ############### Improvements for Accuracy End ###############

    # Store accuracy
    results[name] = accuracy
    print(f"Accuracy of {name}: {accuracy:.4f}")

    # Display confusion matrix for each model
    if name != 'Neural Network':
        cm = confusion_matrix(Y_test, Y_pred)
        sns.heatmap(cm, annot=True, fmt='d')
        plt.title(f'Confusion Matrix - {name}')
        plt.show()

# Display results of all models
print("\nModel Performance Comparison:")
for name, accuracy in results.items():
    print(f"{name}: {accuracy:.4f}")

# Insights and best model selection
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]  # Get the actual best model object
print(f"\nBest model based on accuracy: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Function to get user input
def get_user_input(features):
    while True:
        try:
            input_values = input(f"Enter values for {', '.join(features)} separated by commas (use 0 for default): ")
            user_input = [float(value.strip()) if float(value.strip()) != 0 else 0 for value in input_values.split(',')]
            if len(user_input) != len(features):
                print(f"Please enter exactly {len(features)} values.")
                continue
            return np.array(user_input).reshape(1, -1)
        except ValueError:
            print("Invalid input! Please enter numerical values.")

# Feature names for input
feature_names = list(X.columns)

# Get custom input from the user
custom_input = get_user_input(feature_names)

# Standardize and apply PCA to custom input
custom_input = scaler.transform(custom_input)
custom_input = pca.transform(custom_input)

# Predict using the best model
final_prediction = best_model.predict(custom_input)  # Use the actual model object for prediction

# If Neural Network, ensure it's the right format (softmax output)
if best_model_name == 'Neural Network':
    final_prediction = np.argmax(final_prediction, axis=1)

# Interpret prediction
adhd_classes = ['Typically Developing Children', 'ADHD-Combined', 'ADHD-Hyperactive/Impulsive', 'ADHD-Inattentive']
predicted_class = int(final_prediction[0])

if predicted_class < len(adhd_classes):
    print(f"The Person has: {adhd_classes[predicted_class]}")
else:
    print("Error: Invalid prediction.")